# گزارش گام اول بنچمارک چینوک

این یادداشت خلاصه می‌کند که در گام اول چه تغییرهایی وارد پروژه شد و چطور می‌شود بنچمارک جدید را اجرا و تفسیر کرد.

## چه چیزی اضافه شد؟
- **مجموعه‌داده‌ی جمع‌وجور Chinook**: ماژول `benchmarks/chinook_subset.py` یک نسخه‌ی کوچک و تعیین‌کننده از پایگاه‌دادهٔ Chinook را با چند جدول کلیدی (هنرمند، آلبوم، تراک، مشتری، فاکتور و ...) می‌سازد. دیتابیس هر بار که لازم باشد با تابع `ensure_chinook_subset_db` روی دیسک ساخته می‌شود و نیازی نیست فایل sqlite از قبل داخل مخزن باشد.
- **LLM محلی کاملاً قطعی**: در `benchmarks/benchmark_chinook.py` یک LLM قوانین‌محور تعریف شده که برای هر سؤال مرجع SQL طلایی را برمی‌گرداند. این باعث می‌شود در اجراهای محلی و CI خروجی همیشه تکرارپذیر باشد و بدون کلید API هم بتوان بنچمارک را اجرا کرد.
- **اسکریپت بنچمارک انتهابه‌انتها**: همان فایل `benchmark_chinook.py` کل پایپ‌لاین (Planner → Generator → Safety → Executor → Verifier → Repair) را روی سؤال‌های مرجع اجرا می‌کند، نتیجه را با خروجی طلایی می‌سنجد و خطا، دقت و زمان پاسخ هر کوئری را ذخیره می‌کند.
- **آرتیفکت‌های قابل استناد**: بعد از اجرا چهار فایل تولید می‌شود:
  - `benchmark.jsonl` شامل جزئیات هر سؤال،
  - `summary.json` و `summary.csv` برای خلاصهٔ متریک‌ها،
  - نمودار `latency.svg` که زمان هر کوئری و موفقیت اجرا را نشان می‌دهد.
  شاخه‌ی `benchmarks/results/chinook/latest/` همیشه به آخرین اجرا اشاره می‌کند.
- **به‌روزرسانی README**: بخش "Benchmark Results – Chinook Subset" توضیح می‌دهد چطور بنچمارک را با دستور `make bench-chinook` اجرا کنیم و جدول متریک‌ها + نمودار نمونه را نشان می‌دهد.
- **پوشش تستی**: فایل `tests/test_benchmark_chinook.py` دو سناریو را می‌آزماید؛ ساخت دیتابیس و تولید آرتیفکت‌ها. این باعث می‌شود در CI مطمئن شویم مسیر بنچمارک همیشه سالم است.

## چطور اجرا کنیم؟
```bash
make bench-chinook
```
یا اگر مستقیم می‌خواهید از ماژول استفاده کنید:
```bash
python -m benchmarks.benchmark_chinook --provider local
```

برای استفاده از مدل واقعی (مثلاً OpenAI) می‌شود پارامتر `--provider openai --model <name>` را پاس داد و کلید API را در محیط قرار داد. خروجی‌ها همان مسیر قبلی را به‌روزرسانی می‌کنند.

## خروجی نمونه
جدول متریک‌ها در `benchmarks/results/chinook/latest/summary.csv` ذخیره می‌شود و README نسخهٔ خلاصه‌شدهٔ زیر را نشان می‌دهد:

| متریک | مقدار |
| --- | --- |
| Execution Accuracy | 100% |
| Exact Match | 100% |
| Structural Match | 100% |
| Avg Latency (ms) | 11.51 |
| p95 Latency (ms) | 14.63 |
| Total Cost (USD) | 0.00 |

نمودار `latency.svg` نیز به ازای هر سؤال زمان اجرا و وضعیت موفقیت (✅/❌) را نمایش می‌دهد تا سریع بتوان نقاط کند یا خطادار را شناسایی کرد.

## چرا مهم است؟
- **رزومه‌پسند برای تیم‌های پروداکشن**: نشان می‌دهد فرآیند بنچمارک تکرارپذیر، قابل اسکریپت و قابل استناد است؛ دقیقاً چیزی که شرکت‌هایی مثل دیوار از تیم داده می‌خواهند.
- **دموی تاثیرگذار برای Torob**: با داشتن دیتاست قابل توضیح و نمودار دیداری، می‌توان هنگام دمو یا ارائه روی خروجی‌ها تمرکز کرد و اثر محصول را نشان داد.
